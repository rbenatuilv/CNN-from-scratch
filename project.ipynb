{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto IMT3120\n",
    "## Implementación de Clasificador de Imágenes desde Cero\n",
    "\n",
    "#### Nombre: Roberto Benatuil Valera\n",
    "\n",
    "Este proyecto tendrá como finalidad implementar una red neuronal convolucional para clasificar imágenes. Se buscará implementar las los tipos de capas necesarias, considerando las convolucionales, de pooling, de reshaping y de activación, así como las funciones mismas de activación y de cálculo de pérdida. Cada capa tendrá sus debidos algoritmos de propagación de señales y de gradiente. \n",
    "\n",
    "Al finalizar el modelo, se entrenará con la colección de imágenes del Canadian Institute For Advanced Research, CIFAR10, con el objetivo de comparar su rendimiento con el estado del arte, y analizar su funcionamiento. En este mismo proceso, se realizarán iteraciones y experimentos con diferentes valores de hiperparámetros, entre ellos la tasa de aprendizaje y el tipo y cantidad de capas, así como su tamaño.\n",
    "\n",
    "### Experimentos a realizar\n",
    "\n",
    "Para probar la CNN, se realizarán algunos experimentos, con el fin de analizar su rendimiento y el efecto que los hiperparámetros producen sobre este. Primero, se variará la cantidad de capas convolucionales, cada una con una capa de activación ReLU, con el fin de medir la variación de rendimiento respecto a la eficiencia o rapidez de ejecución.\n",
    "\n",
    "También, se hará otra serie de experimentos en el que se variará la tasa de aprendizaje, que corresponde al nivel de actualización de los parámetros según su gradiente, por cada iteración. Esto, con el fin de medir la velocidad de convergencia y el comportamiento de la curva de error, para encontrar el punto en el que presenta mayor eficiencia.\n",
    "\n",
    "Por último, se intentará hacer una combinación de los resultados anteriores para encontrar el punto de mayor rendimiento.\n",
    "\n",
    "### Por hacer:\n",
    "\n",
    "<ul>\n",
    "\n",
    "<li> Implementar backward propagation de los principales tipos de layers </li>\n",
    "<li> Implementar las funciones propias de convolución, correlación y max pooling </li>\n",
    "<li> Implementar los experimentos de manera clara (solo hay un bosquejo)</li>\n",
    "<li> Perfeccionar las funciones de fit y predict de la CNN</li>\n",
    "\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archivos relevantes:\n",
    "\n",
    "`activation.py`: aquí se definen las funciones de activación disponibles.\n",
    "\n",
    "`aux_functions.py`: se definen funciones auxiliares, como pooling, correlación y convolución.\n",
    "\n",
    "`loss_functs.py`: se definen las funciones de pérdida.\n",
    "\n",
    "`nn_layers.py`: se definen las clases de capas de la red neuronal.\n",
    "\n",
    "`nn_class.py`: se define la clase principal de la CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación y testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from nn_class import ConvNeuralNet\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## CONFIG EXAMPLE ##################\n",
    "\n",
    "layers = [\n",
    "    ('conv',\n",
    "        {\n",
    "            'input_shape': (3, 32, 32),\n",
    "            'kernel_size': 3,\n",
    "            'depth': 5\n",
    "        }\n",
    "    ),\n",
    "    ('maxpool',\n",
    "        {\n",
    "            'kernel_size': 2\n",
    "        }\n",
    "    ),\n",
    "    ('activation',\n",
    "        {\n",
    "            'activation': 'relu'\n",
    "        }\n",
    "    ),\n",
    "    ('reshape',\n",
    "        {\n",
    "            'input_shape': (5, 15, 15),\n",
    "            'output_shape': ((5 * 15 * 15), 1)\n",
    "        }\n",
    "    ),\n",
    "    ('dense',\n",
    "        {\n",
    "            'input_shape': ((5 * 15 * 15), 1),\n",
    "            'neurons': 10\n",
    "        }\n",
    "    ),\n",
    "    ('activation',\n",
    "        {\n",
    "            'activation': 'softmax'\n",
    "        }\n",
    "    )\n",
    "]\n",
    "\n",
    "loss = 'cross_entropy'\n",
    "lr = 0.02\n",
    "\n",
    "################## WORK IN PROGRESS ##################\n",
    "\n",
    "model = ConvNeuralNet(layers, loss, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_channels = x_train.transpose(0, 3, 1, 2)\n",
    "x_test_channels = x_test.transpose(0, 3, 1, 2)\n",
    "\n",
    "y_train_encoded = np.zeros((y_train.size, y_train.max() + 1))\n",
    "y_train_encoded[np.arange(y_train.size), y_train.flatten()] = 1\n",
    "\n",
    "y_test_encoded = np.zeros((y_test.size, y_test.max() + 1))\n",
    "y_test_encoded[np.arange(y_test.size), y_test.flatten()] = 1\n",
    "\n",
    "y_train_encoded = y_train_encoded.reshape(len(y_train_encoded), 10, 1)\n",
    "y_test_encoded = y_test_encoded.reshape(len(y_test_encoded), 10, 1)\n",
    "\n",
    "x_train_channels = x_train_channels / 255\n",
    "x_test_channels = x_test_channels / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo de funcionamiento\n",
    "\n",
    "Ojo: no se recomienda usar fit(), ya que no está optimizado, por lo que se demora un tiempo considerable. Para demostración del funcionamiento de forward propagation se muestra un ejemplo de predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.06316016e-11 3.85363846e-56 4.20118439e-30 7.67552656e-99\n",
      "  7.00343132e-65 2.04491068e-26 3.34046013e-47 1.14517561e-20\n",
      "  1.00000000e+00 4.77018243e-12]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = x_train_channels[0]\n",
    "pred = model.predict(example)\n",
    "\n",
    "print(pred)\n",
    "sum(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
